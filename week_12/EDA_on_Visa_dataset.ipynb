{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c801604e",
   "metadata": {},
   "source": [
    "## PROJECT TO PREDICT MODEL FOR EASY VISA DATASET "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf5371",
   "metadata": {},
   "source": [
    "## Phase 1 : Data Collection and Preparation\n",
    "Task 1.1: Load the dataset into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e6f91",
   "metadata": {},
   "source": [
    "DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd8728",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.14.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing of necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88694ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url= r\"https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/EasyVisa%20(1).csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from pandas\n",
    "data = pd.read_csv(url)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f166ad",
   "metadata": {},
   "source": [
    "PREMILARY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dataset for missing values and handle them appropriately\n",
    "data.shape\n",
    "# From the dataset there are 25480 rows and 12 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ece87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()\n",
    "\n",
    "# From the dataset this indicate that there is no missing value in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "# This reveals all the columns title we have in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()\n",
    "# this indicate that the dataset has no duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04460b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"case_id\"], inplace=True)\n",
    "data.head()\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f8e74",
   "metadata": {},
   "source": [
    "## Phase 2: EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2643d",
   "metadata": {},
   "source": [
    "Descriptive Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a486a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().round(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de021efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "# From the dataset we have 25480 of rows and 9 categorical columns, 2 numerical columns with (int64(2)) and 1 numerical columns with float(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ae65d",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af8e9e",
   "metadata": {},
   "source": [
    "Understanding the dataset and checking out for the unquie values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8351964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of all categorical columns in the  dataset\n",
    "cat_col = list(data.select_dtypes(\"object\").columns)\n",
    "for col in cat_col:\n",
    "    print(data[col].value_counts())\n",
    "    print(\"--\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef9c74",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cd287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_boxplot(data, feature, figsize=(12, 8), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (15,10))\n",
    "    kde: whether to show the density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb863e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = data.copy()\n",
    "\n",
    "\n",
    "\n",
    "# 1. Check for missing values (EDA showed no missing values)\n",
    "print(\"\\n1. Missing Values:\")\n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"No missing values found (as expected from EDA)\")\n",
    "\n",
    "# 2. Check for duplicates\n",
    "print(\"\\n2. Duplicate Rows:\")\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(f\"Percentage of duplicates: {(duplicates/len(data))*100:.2f}%\")\n",
    "\n",
    "# 3. Check skewness for variables identified in EDA as right-skewed\n",
    "print(\"\\n3. Skewness Analysis (EDA identified right-skewed variables):\")\n",
    "skewed_vars = ['no_of_employees', 'prevailing_wage', 'yr_of_estab']\n",
    "for var in skewed_vars:\n",
    "    if var in data.columns:\n",
    "        skewness = data[var].skew()\n",
    "        print(f\"{var}: skewness = {skewness:.3f} ({'right-skewed' if skewness > 0.5 else 'approximately normal'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff230c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=data.select_dtypes(include=['number']).columns\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d115a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_features:\n",
    "    print(f\"\\histogram_boxplot{col}\")\n",
    "    histogram_boxplot(data, col, kde=True, bins=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a8d30",
   "metadata": {},
   "source": [
    "# Identify and handle outliers in the dataset.\n",
    "# From the diagram above, findings from univariate data analysis most data are skewed and there are possible outliers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=data.select_dtypes(include=['object']).columns\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 2, 6))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 2, 6))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n],\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"continent\", perc=False, n=None)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"education_of_employee\", perc=False, n=None)\n",
    "labeled_barplot(data, \"has_job_experience\", perc=False, n=None)\n",
    "labeled_barplot(data, \"requires_job_training\", perc=False, n=None)\n",
    "labeled_barplot(data, \"region_of_employment\", perc=False, n=None)\n",
    "labeled_barplot(data, \"unit_of_wage\", perc=False, n=None)\n",
    "labeled_barplot(data, \"case_status\", perc=False, n=None)\n",
    "labeled_barplot(data, \"full_time_position\", perc=False, n=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f01f239",
   "metadata": {},
   "source": [
    "## Bivariate Analsis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d18393",
   "metadata": {},
   "source": [
    "Numerical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    data[col_list].corr(), annot=True, vmin=1, fmt=\".2f\", cmap=\"Accent\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42690607",
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to plot distributions wrt target\n",
    "\n",
    "\n",
    "def distribution_plot_wrt_target(data, predictor, target):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    target_uniq = data[target].unique()\n",
    "\n",
    "    axs[0, 0].set_title(\"Distribution of target for target=\" + str(target_uniq[0]))\n",
    "    sns.histplot(\n",
    "        data=data[data[target] == target_uniq[0]],\n",
    "        x=predictor,\n",
    "        kde=True,\n",
    "        ax=axs[0, 0],\n",
    "        color=\"teal\",\n",
    "        stat=\"density\",\n",
    "    )\n",
    "\n",
    "    axs[0, 1].set_title(\"Distribution of target for target=\" + str(target_uniq[1]))\n",
    "    sns.histplot(\n",
    "        data=data[data[target] == target_uniq[1]],\n",
    "        x=predictor,\n",
    "        kde=True,\n",
    "        ax=axs[0, 1],\n",
    "        color=\"orange\",\n",
    "        stat=\"density\",\n",
    "    )\n",
    "\n",
    "    axs[1, 0].set_title(\"Boxplot w.r.t target\")\n",
    "    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\"gist_rainbow\")\n",
    "\n",
    "    axs[1, 1].set_title(\"Boxplot (without outliers) w.r.t target\")\n",
    "    sns.boxplot(\n",
    "        data=data,\n",
    "        x=target,\n",
    "        y=predictor,\n",
    "        ax=axs[1, 1],\n",
    "        showfliers=False,\n",
    "        palette=\"gist_rainbow\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b619e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_features:\n",
    "    print(f\"\\distribution_plot_wrt_target{col}\")\n",
    "    distribution_plot_wrt_target(data, col, target=\"case_status\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5c470",
   "metadata": {},
   "source": [
    "Categorical_Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 5, 5))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\", frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f600ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_features:\n",
    "    print(f\"\\stacked_barplot{col}\")\n",
    "    stacked_barplot(data, col, target=\"case_status\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features =data.select_dtypes(include=[np.number]).columns\n",
    "num_features\n",
    "for col in num_features:\n",
    "    print(f'{col} = {data[col].skew():.3f}\"  skewness value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5007993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariate_num_cat(data1, feature, target='case_'):\n",
    "    \"\"\"\n",
    "    Plots and summarizes relationship between a numerical feature and a categorical target.\n",
    "    \"\"\"\n",
    "    print(f\" Feature: {feature} vs {target}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Group summary\n",
    "    summary = data1.groupby(target)[feature].describe()[['mean','std','min','max']]\n",
    "    print(summary)\n",
    "    print()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Boxplot + mean line\n",
    "    sns.boxplot(x=target, y=feature, data=data1, palette='Set2')\n",
    "    plt.title(f'{feature} across {target} categories', fontsize=13)\n",
    "    plt.xlabel(target)\n",
    "    plt.ylabel(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in num_features:\n",
    "#     for col2 in cat_features:\n",
    "#         if col2 ==\"case_Status\":\n",
    "            # bivariate_num_cat(data, col, col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4134e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=data, x=\"continent\", y=\"yr_of_estab\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af8d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=data, x=\"no_of_employees\", y=\"case_status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = data.copy()\n",
    "\n",
    "\n",
    "\n",
    "# 1. Check for missing values (EDA showed no missing values)\n",
    "print(\"\\n1. Missing Values:\")\n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"No missing values found (as expected from EDA)\")\n",
    "\n",
    "# 2. Check for duplicates\n",
    "print(\"\\n2. Duplicate Rows:\")\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(f\"Percentage of duplicates: {(duplicates/len(data))*100:.2f}%\")\n",
    "\n",
    "# 3. Check skewness for variables identified in EDA as right-skewed\n",
    "print(\"\\n3. Skewness Analysis (EDA identified right-skewed variables):\")\n",
    "skewed_vars = ['no_of_employees', 'prevailing_wage', 'yr_of_estab']\n",
    "for var in skewed_vars:\n",
    "    if var in data.columns:\n",
    "        skewness = data[var].skew()\n",
    "        print(f\"{var}: skewness = {skewness:.3f} ({'right-skewed' if skewness > 0.5 else 'approximately normal'})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baca7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def temp_encode_for_correlation_check(df, target_col, figsize=(10,2)):\n",
    "    \"\"\"\n",
    "    Plots a heatmap showing correlation of each numeric feature against target_col.\n",
    "    Returns a Series of correlations (sorted by absolute magnitude).\n",
    "    \"\"\"\n",
    "    # make a temporary copy\n",
    "    df_temp = df.copy()\n",
    "    # Encode categorical columns temporarily\n",
    "    label_encoders = {}\n",
    "    for col in df_temp.select_dtypes(include=[\"object\", \"category\"]).columns:\n",
    "        le = LabelEncoder()\n",
    "        df_temp[col] = le.fit_transform(df_temp[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    corrs = df_temp.corrwith(df_temp[target_col]).drop(target_col)\n",
    "    corrs_df = corrs.to_frame(name='corr').T  # shape (1, n)\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(\n",
    "        corrs_df,\n",
    "        annot=True,\n",
    "        fmt=\".3f\",\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        cbar_kws={'orientation': 'vertical', 'shrink':0.7}\n",
    "    )\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks([0], [target_col], rotation=0)\n",
    "    plt.title(f'Correlation of numeric features with {target_col}', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # return sorted correlations for downstream use\n",
    "    return corrs.reindex(corrs.abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80674f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_encode_for_correlation_check(data,'case_status', figsize=(10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_with_target(data, target_col, figsize=(10,2)):\n",
    "    \"\"\"\n",
    "    Plots a heatmap showing correlation of each numeric feature against target_col.\n",
    "    Returns a series of correlations (sorted by absolute magnitude).\n",
    "    \"\"\"\n",
    "    # Keep only numeric columns\n",
    "    df_duplicate= data.copy()\n",
    "\n",
    "\n",
    "    # compute correlations of every numeric column with the target\n",
    "    corrs = df_duplicate.corrwith(df_duplicate[target_col]).drop(target_col)\n",
    "\n",
    "    corrs_df = corrs.to_frame(name='corr').T  # shape (1, n)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(\n",
    "        corrs_df,\n",
    "        annot=True,\n",
    "        fmt=\".3f\",\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        cbar_kws={'orientation': 'vertical', 'shrink':0.7}\n",
    "    )\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks([0], [target_col], rotation=0)\n",
    "    plt.title(f'Correlation of numeric features with {target_col}', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # return sorted correlations for downstream use\n",
    "    return corrs.reindex(corrs.abs().sort_values(ascending=False).index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cfe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_Visa_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
